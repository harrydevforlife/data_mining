---
title: "Lab 2 - Classification"
author: "Tran Cong Tuan Manh"
date: "2022/03/08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Câu hỏi 1
Trong bài hướng dẫn, ta đã áp dụng `random forest` trên tập dữ liệu `Boston` dùng `mtry=6` và `ntree=25`, `ntree=500`. Bây giờ, bạn hãy tạo một biểu đồ (tương tự như trong slide 21) mô tả `test error` của `random forest`trên tập dữ liệu này theo `mtry` và `ntree` dùng một miền giá trị cho `mtry` và `ntree`. Mô tả kết quả thu được.
```{r }
# Viết mã R của bạn ở đây
library(randomForest)
library(MASS)
data(Boston)
attach(Boston)
dim(Boston)

```

```{r }
set.seed(134)
# Tạo tập train và test
train <- sample(1:nrow(Boston), nrow(Boston)/3)

x.train <- Boston[train, -14]
y.train <- Boston[train, 14]
x.test <- Boston[-train, -14]
y.test <- Boston[-train, 14]
```

```{r }
# Tạo cây với mtry=6 và ntree= 25 & 500
rf.1 <- randomForest(x=x.train, y=y.train, xtest=x.test, ytest=y.test, mtry=6, ntree=25)
rf.2 <- randomForest(x=x.train, y=y.train, xtest=x.test, ytest=y.test, mtry=6, ntree=500)

```

```{r }
which.min(rf.1$test$mse)
which.min(rf.2$test$mse)
```


```{r }
plot(1:500, rf.2$test$mse, type='l', col='blue', xlab="Number of trees", ylab = "Test MSE", ylim=c(13, 30))
lines(1:25, rf.1$test$mse, type='l', col="orange")
legend("topright", legend=c("ntree=25", "ntree=500"), col=c("orange", "blue"), lty=1, cex=1)
points(which.min(rf.1$test$mse), rf.1$test$mse[24], col="red", cex=2)
points(which.min(rf.2$test$mse), rf.2$test$mse[362], col="red", cex=2)
```

Giải thích kết quả: 
Chúng ta có thể thấy rằng giá trị "test MSE" nhỏ nhất của hai mô hình, với mô hình có 25 cây có giá trị "test MSE" nhỏ nhất tại cây số 24. Mô hình 500 cây có giá trị "test MSE" nhỏ nhất tại cây 362.  


## Câu hỏi 2
Trong bài hướng dẫn, ta đã tạo một `classiﬁcation tree` trên tập dữ liệu `Carseats` sau khi chuyển biến `Sales` thành biến categorical là `High`. Bây giờ, bạn hãy dự đoán biến `Sales` dùng `regression tree`, xem biến này là biến numeric.

a. Chia dữ thành `training set` và `test set`.
```{r }
# Viết mã R của bạn ở đây
library(tree)
library(ISLR2)
attach(Carseats)

```

```{r }
set.seed(456)
train <- sample(1:nrow(Carseats), nrow(Carseats)/3)
Carseats.train <- Carseats[train, ]
Carseats.test <- Carseats[-train, ]
y.test <- Carseats.test$Sales
```

b. Fit một `regression tree` trên `training set`. Vẽ tree thu được và diễn giải kết quả. Cho biết `test MSE` là bao nhiêu?
```{r }
# Viết mã R của bạn ở đây
carseats.tree <- tree(Sales ~ ., data=Carseats.train)
summary(carseats.tree)

```
```{r }
plot(carseats.tree)
text(carseats.tree, pretty=0)
```

```{r }
carseats.tree
```


```{r }
#Test MSE
ypredict <- predict(carseats.tree, newdata=Carseats.test)
mean((ypredict - y.test)^2)
```


c. Sử dụng `cross-validation` để xác định mức độ phức tạp tối ưu của cây. Việc `pruning` (cắt tỉa cây) có cải thiện `test MSE` không?
```{r }
# Viết mã R của bạn ở đây
cv.Carseats <- cv.tree(carseats.tree)
plot(cv.Carseats$size, cv.Carseats$dev, type='b')
```
```{r}
prune.Carseats <- prune.tree(carseats.tree, best=11)
plot(prune.Carseats)
text(prune.Carseats, pretty=0)
```
```{r}
ypredict <- predict(prune.Carseats, Carseats.test)
mean((ypredict-y.test)^2)
```
Kết luận: Việc cắt tỉa cây khiến test MSE cao hơn.

d. Sử dụng `bagging` để phân tích tập dữ liệu này. Cho biết `test MSE` thu được là bao nhiêu? Sử dụng hàm `importance()` để xác định biến quan trọng nhất.
```{r }
# Viết mã R của bạn ở đây
require(randomForest)
bag.Carseats <- randomForest(Sales ~., data=Carseats.train, mtry=10, importance=TRUE)
```

```{r}
ypredict.bag <- predict(bag.Carseats, newdata=Carseats.test)
mean((ypredict.bag-y.test)^2)
```
"bagging" giảm test MSE xuống còn 3.2  

```{r}
importance(bag.Carseats)
```

```{r}
varImpPlot(bag.Carseats)
```
Kết luận: Có hai biến quan trọng nhất là Price và ShelveLoc.  


e. Sử dụng `random forest` để phân tích tập dữ liệu này. Cho biết `test MSE` thu được là bao nhiêu? Sử dụng hàm `importance()` để xác định biến quan trọng nhất. Mô tả hiệu quả của `m`, số biến được xem xét để tách, trên `error rate` thu được.
```{r }
# Viết mã R của bạn ở đây
rf.Carseats <- randomForest(Sales~., data=Carseats.train, mtry=floor((ncol(Carseats)-1)/3),importance=TRUE)
```


```{r }
ypredict.rf <- predict(rf.Carseats, newdata = Carseats.test)
mean((ypredict.rf-y.test)^2)
```
```{r}
importance(rf.Carseats)
```

```{r}
varImpPlot(rf.Carseats)
```
Kết luận: biến quan trọng nhất là Price và ShelveLoc.  


## Câu hỏi 3
Câu hỏi này liên quan đến tập dữ liệu `OJ` của thư viện `ISLR`.

a. Tạo một `training set` chứa một mẫu ngẫu nhiên gồm 800 điểm dữ liệu, và một `test set` chứa các điểm dữ liệu còn lại.
```{r }
# Viết mã R của bạn ở đây
require(ISLR)
data(OJ)
attach(OJ)
set.seed(87)
train_3a <- sample(1:nrow(OJ), 800)
train_OJ <- OJ[train_3a, ]
test_OJ <- OJ[-train_3a, ]
```



b. Fit một tree trên `training data`, với `Purchase` là output và các biến khác là input. Sử dụng hàm `summary()` để tạo một `summary statistics` về cây thu được. Mô tả kết quả thu được. Cho biết `training error rate` là bao nhiêu? Cây có bao nhiêu `terminal node`?
```{r }
# Viết mã R của bạn ở đây
require(tree)
tree_OJ <- tree(Purchase ~., data=train_OJ) # There's no variable "Buy" in this dataset
summary(tree_OJ)
```
Traning error: 0.1538.  
Có 9 terminal nodes.  


c. Liệt kê chi tiết về output của cây bằng cách dùng tên của `tree object`. Chọn một `terminal node` và giải thích thông tin nó thể hiện.
```{r }
# Viết mã R của bạn ở đây
tree_OJ
```

d. Tạo một biểu đồ của cây và giải thích kết quả.
```{r }
# Viết mã R của bạn ở đây
plot(tree_OJ)
text(tree_OJ, pretty=0)
```
Kết luận: Biến LoyalCH chia nhánh ở lần đầu tiên nên có nhiều khả năng là biến quan trọng. Còn có biến PriceDiff với 2 lần chia nhánh.  


e. Dự đoán output trên `test set` và tạo một `confusion matrix` để so sánh `actual test labels` với `predicted test labels`. Cho biết `test error rate`?
```{r}
# Viết mã R của bạn ở đây
y_test_OJ <- test_OJ$Purchase

tree_pred <- predict(tree_OJ, test_OJ, type="class")
table(tree_pred, y_test_OJ)
```
```{r}
testerror <- (21 + 37)/(150 + 37 + 21 + 62)
print(testerror)
```
Test error: 21.48%.  


f. Áp dụng hàm `cv.tree()` trên `training set` để xác định `optimal tree size`.
```{r }
# Viết mã R của bạn ở đây
cv_tree <- cv.tree(tree_OJ, FUN=prune.misclass)
cv_tree
```
Kết luận: `optimal tree size` tại node thứ 9,8,5 đều có Cross-validation thất nhất là 141.  


g. Tạo một biểu đồ với `tree size` trên `x-axis` và `cross-validated classiﬁcation error rate` trên `y-axis`.
```{r }
# Viết mã R của bạn ở đây
plot(cv_tree$size, cv_tree$dev, type='b')
```

h. Cho biết `tree size` nào tương ứng với `cross-validated classiﬁcation error rate` nhỏ nhất?

`cross-validated classiﬁcation error rate` nhỏ nhất (141) xảy ra khi kích thước cây là 8.  



i. Tạo một `pruned tree` tương ứng với `optimal tree size` dùng `cross-validation`. Nếu `cross-validation` không cho ra kết quả là một `pruned tree` thì tạo một `pruned tree` với 5 `terminal nodes`.
```{r }
# Viết mã R của bạn ở đây
prune_OJ <- prune.misclass(tree_OJ, best=5)
summary(prune_OJ)
```
trainning errow ở cây mới là 15.88%.  

j. So sánh `training error rate` giữa `pruned tree` và `unpruned tree`. Cây nào cho kết quả tốt hơn?

`training error rate` cây dùng `pruned tree`(15.88%) cho kết quả không tốt bằng `unpruned tree`(15.38%).  


k. So sánh `test error rate` giữa `pruned tree` và `unpruned tree`. Cây nào cho kết quả tốt hơn?
```{r }
# Viết mã R của bạn ở đây
prune_predict <- predict(prune_OJ, test_OJ, type = "class")
table(prune_predict, y_test_OJ)
```

```{r}
testerror <- (33 + 29)/(138 + 70 + 33 + 29)
print(testerror)
```
Test error: 22.96%.  
`unpruned tree` cho kết quả tốt hơn với test error là 21.48%.  

## Câu hỏi 4
Ta sẽ sử dụng `boosting` để sự đoán `Salary` trong tập dữ liệu `Hitters`.

```{r}
require(ISLR)
data(Hitters)
attach(Hitters)
```


a. Loại bỏ những dòng trong tập dữ liệu mà giá trị `Salary` là không có hoặc không biết, sau đó lấy `log` của `Salary`.
```{r }
# Viết mã R của bạn ở đây
summary(Hitters$Salary)
```

```{r}
Hitters <- na.omit(Hitters)
summary(Hitters$Salary)
```

```{r}
Hitters$Salary <- log(Hitters$Salary)
```



b. Tạo một `training set` gồm 200 điểm dữ liệu đầu tiên và `test set` là các điểm dữ liệu còn lại trong tập dữ liệu.

```{r}
nrow(Hitters)
```

```{r }
# Viết mã R của bạn ở đây
train_Hit <- Hitters[1:200, ]
test_Hit <- Hitters[201:263, ]
```

c. Thực hiện `boosting` trên `training set` với `1,000 trees` dùng một dãy các giá trị cho tham số $\lambda$ (`shrinkage parameter`). Tạo một biểu đồ với `x-axis` là các giá trị $\lambda$  khác nhau và `y-axis` là `training set MSE` tương ứng.
```{r }
# Viết mã R của bạn ở đây
library(gbm)
```
```{r}
lambda_vals <- seq(from=0.001, to=1, by=0.05)
train_error <- rep(NA, length(lambda_vals))
for (l in 1:length(lambda_vals)) {
  boost_Hitt <- gbm(Salary~., 
                  data=train_Hit, 
                  distribution = "gaussian",
                  n.trees = 1000,
                  shrinkage=lambda_vals[l])
  train_predict <- predict(boost_Hitt, train_Hit, n.trees=1000)
  train_error[l] <- mean((train_predict- train_Hit$Salary)^2)
}

plot(lambda_vals, train_error, type="b", xlab="Shrinkage values", ylab="Training set MSE")
```

```{r}
which.min(train_error)
```

```{r}
train_error[20]
```

```{r}
lambda_vals[20]
```



d. Tạo một biểu đồ với `x-axis` là các giá trị $\lambda$  khác nhau và `y-axis` là `test set MSE` tương ứng. 
```{r }
# Viết mã R của bạn ở đây
lambda_vals <- seq(from=0.001, to=1, by=0.05)
test_error <- rep(NA, length(lambda_vals))
for (l in 1:length(lambda_vals)) {
  boost_Hitt <- gbm(Salary~., 
                  data=train_Hit, 
                  distribution = "gaussian",
                  n.trees = 1000,
                  shrinkage=lambda_vals[l])
  test_predict <- predict(boost_Hitt, test_Hit, n.trees=1000)
  test_error[l] <- mean((test_predict - test_Hit$Salary)^2)
}


plot(lambda_vals, test_error, type="b", xlab="Shrinkage values", ylab="Test set MSE")
```

```{r}
which.min(test_error)
```

```{r}
test_error[2]
```

```{r}
lambda_vals[2]
```

e. Cho biết biến nào là biến quan trọng nhất trong `boosted model`?
```{r}
# Viết mã R của bạn ở đây
summary(boost_Hitt)
```
Biến quan trọng nhất trong boost model là CAtBat.  


f. Áp dụng `bagging` và `random forest` trên `training set` với các tham số mà bạn cho là tốt nhất. So sánh `test MSE` của `boosting` với `test MSE` của `random forest` và `bagging`.
```{r }
# Viết mã R của bạn ở đây
require(randomForest)

bag.Hit <- randomForest(Salary ~ .,
                        data=train_Hit,
                        mtry=19,
                        importance=TRUE,
                        n.trees=1000)

bag.pred <- predict(bag.Hit, newdata=test_Hit)
mean((bag.pred-test_Hit$Salary)^2)
```
Test error của `bagging` nhở hơn `boosting` 0.03%.  

```{r }
# Viết mã R của bạn ở đây
require(randomForest)
rf.Hit <- randomForest(Salary ~., data=train_Hit, mtry=10, importance=TRUE)
```

```{r}
ypredict.Hit <- predict(rf.Hit, newdata=test_Hit)
mean((ypredict.Hit-test_Hit$Salary)^2)
```
Test errow của `RandomForest` thấp hơn `bagging` 0.1% và thấp hơn `boosting` 0.4%.  
