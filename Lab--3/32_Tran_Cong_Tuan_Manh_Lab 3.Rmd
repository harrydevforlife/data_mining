---
title: "Lab 3 - Clustering Assignments"
author: "Tran Cong Tuan Manh"
date: "2022/04/05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

### Câu hỏi 1 (4 điểm)
Ở câu hỏi này, bạn sẽ tiếp tục sử dụng các thuật toán `kmeans` và `hclust` trên tập dữ liệu `USArrests` nhưng có thực hiện thêm một số bước.


#### a. (0.5 điểm)	Áp dụng hàm `scale()` trên dữ liệu trước khi thực hiện `k-means` (xem mục 2 trong phần hướng dẫn).

```{r 1a}
df <- USArrests
summary(df)
df_scale <- scale(df)
summary(df_scale)
```


#### b.	(0.5 điểm) Không áp dụng hàm `scale()` nhưng áp dụng PCA trên dữ liệu, sau đó thực hiện k-means với số cụm là `k = 4` trên trên 2 thành phần chính đầu tiên và minh họa kết quả dùng hàm `plot`. Bình luận kết quả thu được.

```{r 1b}
set.seed(123)
kmean_df <- kmeans(df, centers = 4, nstart = 50)
#Simple visualisation of clusters 
USArrestsPC <- princomp(USArrests)

plot(USArrestsPC$scores[,1:2], col=kmean_df$cluster, main="Clustering results (with PCA)")
points(kmean_df$centers, pch=3, cex=2)
```



#### c.	(1 điểm) Áp dụng hàm `scale()` trên dữ liệu trước khi thực hiện gom cụm phân cấp dùng các phương pháp `single`, `complete`, `average` và `median` trên tập dữ liệu `USArrests`.

```{r 1c}
hcl_com = hclust( dist(df_scale), method="complete" )
plot(hcl_com)
```
```{r}
hcl_sin = hclust( dist(df_scale), method="single" )
plot(hcl_sin)
```
```{r}
hcl_ave = hclust( dist(df_scale), method="average" )
plot(hcl_ave)
```
```{r}
hcl_med = hclust( dist(df_scale), method="median" )
plot(hcl_med)
```


#### d.	(0.5 điểm) Cắt dendrogram để thu được 2, 3, 4 cụm. Cho biết kết quả gom cụm tương ứng.

```{r 1d}
cutree(hcl_com,2)
```
```{r }
cutree(hcl_com,3)
```

```{r }
cutree(hcl_com,4)
```

```{r}
cutree(hcl_sin,2)
```

```{r}
cutree(hcl_sin,3)
```

```{r}
cutree(hcl_sin,4)
```

```{r}
cutree(hcl_ave,2)
```

```{r}
cutree(hcl_ave,3)
```

```{r}
cutree(hcl_ave,4)
```

```{r}
cutree(hcl_med,2)
```

```{r}
cutree(hcl_med,3)
```

```{r}
cutree(hcl_med,4)
```


#### e. (0.5 điểm) Hãy cho biết ảnh hưởng của việc scaling đối với các kết quả thu được? Ta có nên thực hiện scaling trước khi áp dụng các thuật toán? Hãy chứng minh câu trả lời của bạn.

Trả lời: 


#### f. (0.5 điểm) So sánh Dunn index của các kết quả gom cụm khi áp dụng các thuật toán trên.

```{r 1f, include=FALSE}
#install.packages("clValid",dependencies = TRUE)
library(clValid)
```

```{r}
d <- dist(USArrests, method="euclidean")
hcl_com <- hclust(d, "complete")
hcl_com.cluster <- cutree(hcl_com, k = 2)
dunn(d, hcl_com.cluster)
dunn(d, kmean_df$cluster)
```




#### g.	(0.5 điểm) So sánh chỉ số Silhouette của các kết quả gom cụm khi áp dụng các thuật toán trên.

```{r 1g}
d <- dist(USArrests, method="euclidean")
hcl_com <- hclust(d, "complete")
hcl_com.cluster <- cutree(hcl_com, k = 2)
cl1 <- silhouette(hcl_com.cluster, d)
mean(cl1[, 3])
cl2 <- silhouette(kmean_df$cluster, d)
mean(cl2[, 3])
```





### Câu hỏi 2 (6) điểm
Thực hiện thuật toán `kmeans` và `hclust` và `dbscan` cho tập dữ liệu `iris`.

#### a. (1 điểm)	Áp dụng `kmeans` với `k = 3` trên tập dữ liệu `iris` sau khi loại bỏ nhãn (thuộc tính `Species`) khỏi tập dữ liệu.

```{r 2a}
data(iris)
iris_s = iris[iris$Species=="setosa",1:4]
set.seed(1)
iris.cluster <- kmeans(iris_s, center = 3, nstart = 20)
print(iris.cluster)
```


#### b. (1 điểm)	Áp dụng `hclust` và cắt dendrogram với k = 3 trên tập dữ liệu `iris` sau khi loại bỏ nhãn (thuộc tính `Species`) khỏi tập dữ liệu.

```{r 2b}
library(dendextend)
hc.centroid <- hclust(dist(iris_s), "centroid")
plot(hc.centroid, main="Centroid Linkage", xlab="", sub ="", cex =.9)
```
```{r}
dendro <- as.dendrogram(hclust(dist(iris_s[1:3,])))
labels_colors(dendro) <- 1:3
labels_colors(dendro)
```

```{r}
plot(dendro, main = "dendrogram")
```




#### c. (1 điểm) Áp dụng `dbscan` trên tập dữ liệu `iris` sau khi loại bỏ nhãn (thuộc tính Species) khỏi tập dữ liệu.
Hãy thử nghiệm với các tham số `eps` và `minPts` khác nhau và chọn các tham số bạn cho là tốt nhất. Bạn có chiến lược nào để chọn các tham số này không?


```{r}
plot(iris_s, pch=20)
```

```{r}
library(dbscan)
scan <- dbscan(iris_s, eps = 0.5, minPts = 8)
scan
```

```{r}
plot(iris_s, col = scan$cluster + 1L, pch = scan$cluster + 1L)
```



#### d.	(3 điểm) Sử dụng thuộc tính `Species` làm nhãn cụm thật sự, hãy tính và so sánh Precison, Recall, và F-measure của kết quả gom cụm (theo công thức được định nghĩa như bên dưới) khi dùng `kmeans`, `hclust` và `dbscan`.

```{r }

```

Giả sử tập dữ liệu $D$ có $n$ phần tử $x_i$ được phân hoạch thành $p$ nhóm (ở đây ứng với số loài). Gọi $y_i \in \{1, 2, · · · , p\}$ là nhóm thật sự (ground-truth labels) cho mỗi phần tử. Ground-truth clustering được cho bởi $T = \{T_1, T_2, \cdots , T_p\}$, với $T_j$ bao gồm tất cả các phần tử có nhãn $j$, nghĩa là, $T_j = \{ x_i \in D | y_i = j \}$. Mặt khác, gọi $C = \{ C_1, C_2, \cdots, C_k \}$ là một kết quả gom cụm của $D$ thành $k$ cụm (cluster), qua một thuật toán gom cụm nào đó, và $\hat{y_i} \in \{ 1, 2, \cdots, k \}$ là cluster label cho $x_i$. Ta sẽ xem $T$ là một phân hoạch chuẩn (ground-truth partitioning) và mỗi $T_i$ là một phân vùng (partition). Ta gọi $C$ là một kết quả gom cụm (clustering), với mỗi $C_i$ là một cụm (cluster). Giả sử ground truth là biết trước, một thuật toán gom cụm sẽ thực hiện gom cụm trên $D$ với số cụm chính xác, tức với $k = p$. Tuy nhiên, để giữ tính tổng quát, ta cho phép $k \ne p$.

```{r, results = "asis", echo = FALSE, message = FALSE}
library(knitr)

tex2markdown <- function(texstring) {
  writeLines(text = texstring,
             con = myfile <- tempfile(fileext = ".tex"))
  texfile <- pandoc(input = myfile, format = "html")
  cat(readLines(texfile), sep = "\n")
  unlink(c(myfile, texfile))
}

textable <- "
\\begin{table}
    \\caption{Contingency table of clustering results}
    \\centering
    \\begin{tabular}{|c|c|c|c|c|}
    \\hline
    Clusters/Species & $T_1$ & $T_2$ & $...$ & $T_p$ \\\\
    \\hline
    $C_1$ & $n_{11}$ & $n_{12}$ & $...$ & $n_{1p}$ \\\\
    \\hline
    $C_2$ & $n_{21}$ & $n_{22}$ & $...$ & $n_{2p}$ \\\\
    \\hline
    $...$ & $...$ & $...$ & $...$ & $...$ \\\\
    \\hline
    $C_k$ & $n_{k1}$ & $n_{k2}$ & $...$ & $n_{kp}$ \\\\
    \\hline
    \\end{tabular}
\\end{table}
"

tex2markdown(textable)
```


```{=latex}
\begin{table}
    \caption{Contingency table of clustering results}
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Clusters/Species & $T_1$ & $T_2$ & $\cdots$ & $T_p$ \\
    \hline
    $C_1$ & $n_{11}$ & $n_{12}$ & $\cdots$ & $n_{1p}$\\
    \hline
    $C_2$ & $n_{21}$ & $n_{22}$ & $\cdots$ & $n_{2p}$\\
    \hline
    $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$\\
    \hline
    $C_k$ & $n_{k1}$ & $n_{k2}$ & $\cdots$ & $n_{kp}$\\
    \hline
    \end{tabular}
    \label{tab:contingency_table}
\end{table}
```

Các độ đo đánh giá kết quả gom cụm cố gắng nắm bắt mức độ mà các phần tử từ cùng một phân vùng (partition) xuất hiện trong cùng một cụm (cluster) và mức độ mà các phần tử từ các phân vùng (partition) khác nhau được nhóm thành các cụm (cluster) khác nhau. Những độ đo này dựa trên $k \times p$ contingency table $N$ (xem Table \ref{tab:contingency_table}) được thành lập dựa vào một kết quả gom cụm (clustering) $C$ và một phân hoạch chuẩn (ground-truth partitioning) $T$, được định nghĩa như sau:

$$N(i, j) = n_{ij} = |C_i \cap T_j|$$

- $Recall$ là tỷ lệ đối tượng cùng loài được gán cùng cụm.

- $Precision$ là tỷ lệ đối tượng được gán cùng cụm thuộc cùng loài.

- $F{\text -}measure$ là một độ đo cân bằng giữa $Precision$ và $Recall$ và được tính bằng trung bình điều hòa giữa $Precision$ và $Recall$. Đây là một độ đo thường được sử dụng để so sánh các thuật toán gom cụm với nhau.

Các độ đo $Precision$, $Recall$, và $F{\text -}measure$ được tính từ Table \ref{tab:contingency_table} dùng các công thức sau:

$$
\begin{equation}
precision = \frac{{\sum\limits_{i = 1}^k {\mathop {{\rm{max}}}\limits_{j \in \left\{ {1, \ldots p} \right\}} \{n_{ij}\} } }}{{\sum\limits_{i = 1}^k {\sum\limits_{j = 1}^p {n_{ij} } } }}
\end{equation}
$$

$$
\begin{equation}
recall = \frac{{\sum\limits_{j = 1}^p {\mathop {{\rm{max}}}\limits_{i \in \left\{ {1, \ldots ,k} \right\}} \{n_{ij}\} } }}{{\sum\limits_{i = 1}^k {\sum\limits_{j = 1}^p {n_{ij} } } }}
\end{equation}
$$

$$
\begin{equation}
\begin{split}
F{\text -}measure = \frac{{2 \cdot precision \cdot recall}}{{precision + recall}}
\end{split}
\end{equation}
$$
